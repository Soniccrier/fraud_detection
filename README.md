# fraud_detection
ğŸ“Œ Credit Card Fraud Detection â€“ Machine Learning Project
This project builds a fraud detection model using the popular Credit Card Fraud Dataset.
It demonstrates data preprocessing, handling imbalanced data, model training, and evaluating performance using industry-standard metrics such as ROC-AUC.
The goal is to detect fraudulent transactions from anonymized credit card data.

ğŸ“‚ Project Structure
The notebook performs the following steps:
    1. Load and inspect the dataset
    2. Explore class imbalance
    3. Visualize fraud vs non-fraud counts
    4. Scale important numeric features
    5. Train a Logistic Regression model
    6. Generate predictions
    7. Evaluate the model using:
        â—¦ Classification Report
        â—¦ Confusion Matrix
        â—¦ ROC-AUC Score

ğŸ“Š Dataset Description
The dataset contains 284,807 credit card transactions with the following columns:
    â€¢ Time â€“ Number of seconds elapsed between each transaction
    â€¢ V1â€“V28 â€“ PCA-transformed features (sensitive data anonymized)
    â€¢ Amount â€“ Transaction amount
    â€¢ Class â€“ Target variable
        â—¦ 0 â†’ Normal transaction
        â—¦ 1 â†’ Fraudulent transaction
The dataset is highly imbalanced (fraud â‰ˆ 0.17%), which makes evaluation metrics more important than accuracy alone.

ğŸ” Exploratory Data Analysis (EDA)
    â€¢ Checked dataset size, info, and missing values
    â€¢ Analyzed distribution of Class (fraud vs non-fraud)
    â€¢ Used a Seaborn barplot to visualize the imbalance
Example visualization used:
class_count = df.groupby('Class', as_index=False).size()
class_count.rename(columns={'size': 'count'}, inplace=True)
class_count = class_count.sort_values('count', ascending=False)

plt.figure(figsize=(12,6))
ax = sns.barplot(data=class_count, x='Class', y='count')
for container in ax.containers:
    ax.bar_label(container, fmt='%1.0f', label_type='edge', color='black')

plt.title("Fraud vs Non-Fraud Count")
plt.xlabel("Class (0 = Non-Fraud, 1 = Fraud)")
plt.ylabel("Transaction Count")
plt.show()

âš™ï¸ Data Preprocessing
The columns Amount and Time were scaled using StandardScaler to bring all values into a comparable range:
scaler = StandardScaler()
df['scaled_amount'] = scaler.fit_transform(df['Amount'].values.reshape(-1, 1))
df['scaled_time'] = scaler.fit_transform(df['Time'].values.reshape(-1, 1))
df = df.drop(['Amount', 'Time'], axis=1)
This improves model performance and stability.

ğŸ¤– Model Training
A Logistic Regression model was trained:
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)
Why Logistic Regression?
    â€¢ Fast to train
    â€¢ Works well on linearly separable problems
    â€¢ Excellent baseline for fraud detection

ğŸ“ˆ Model Evaluation
The model was evaluated using:
    â€¢ Classification Report
    â€¢ Confusion Matrix
    â€¢ ROC-AUC Score
The project achieved:
â­ ROC-AUC = 0.957
This means the model correctly distinguishes fraud vs. non-fraud 95.7% of the time, which is very strong for a baseline model on an imbalanced dataset.

ğŸš€ Key Takeaways
    â€¢ Fraud detection datasets are extremely imbalanced
    â€¢ ROC-AUC is a better metric than accuracy
    â€¢ Logistic Regression performs surprisingly well
    â€¢ Feature scaling improves performance
    â€¢ Visualizations help explain fraud patterns

ğŸ“ Technologies Used
    â€¢ Python
    â€¢ Pandas
    â€¢ NumPy
    â€¢ Seaborn
    â€¢ Matplotlib
    â€¢ Scikit-learn
